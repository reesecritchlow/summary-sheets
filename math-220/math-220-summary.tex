\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper, portrait, margin=1in]{geometry}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\setlength\parindent{0pt}
\usepackage{enumerate}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{fancyhdr}
\usepackage{tcolorbox}

\newcommand{\suchthat}{\textrm{ s.t. }}

\usepackage{calligra}
\DeclareMathAlphabet{\mathcalligra}{T1}{calligra}{m}{n}
\DeclareFontShape{T1}{calligra}{m}{n}{<->s*[2.2]callig15}{}

\newcommand{\sepvec}{\vec{r_\textrm{sep}}}
\newcommand{\sephat}{\hat{r}_{\textrm{sep}}}

\newcommand{\kfrac}{\frac{1}{4\pi\epsilon_0}}

\newcommand{\scripty}[1]{\ensuremath{\mathcalligra{#1}}}

\newcommand{\set}[1]{\left\{ #1 \right\}}
%% We also redfine the negation symbol:
\renewcommand{\neg}{\sim}

\newcommand{\header}[1]{\begin{large}\noindent #1\end{large}\\\rule{\textwidth}{0.5pt}}
\newcommand{\gap}{\medskip\\}
\newcommand{\sheader}[1]{\underline{#1:}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\centertext}[1]{\begin{center}#1\end{center}}



\newcommand{\curly}[1]{\left\{#1\right\}}

\newcommand{\sgap}{\smallskip\\}
\newcommand{\zeroset}{\curly{0}}

\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}




\newcommand{\bfrac}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\formula}[3]{\begin{center} \begin{tcolorbox}[title = #2] $$#3$$\end{tcolorbox}\end{center}}
\newcommand{\where}{\hspace{0.5cm} \textrm{where} \hspace{0.5cm}}
\newcommand{\hgap}{\hspace{0.5cm}}
\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\jomega}{{j\omega}}
\newcommand{\domega}{d\omega}

\newcommand{\doubleformula}[4]{\begin{center} \begin{tcolorbox}[title = #2] $$#3$$\\$$#4$$\end{tcolorbox}\end{center}}

\newcommand{\tripleformula}[5]{\begin{center} \begin{tcolorbox}[title = #2] $$#3$$\\$$#4$$\\$$#5$$\end{tcolorbox}\end{center}}

\title{PHYS 301 Notes}
\author{reesecritchlow }
\date{September 2022}

\begin{document}

\begin{center}
    \Large MATH 220 Notes\\
    \normalsize Reese Critchlow
\end{center}

\header{Sets}

\sheader{Sets} A \textbf{set} is a collection of objects. The objects are referred to 
as \textbf{elements} of \textbf{members} of the set.
\sgap
For sake of notation, sets are generally described as capital letters $A, B, C, X, Y$, and
members of a set are described as their respective lowercase letters $a,b,c,x,y$.
\sgap
Integers are generally referred to as $i,j,k,l,m,n$ and reals are generally referred to 
as $x,y,z,w$.
\sgap
\sheader{Set Notation} Sets can also describe membership by means of curly braces. 
\[
    A = \{1, 2, 3\}    
\]
Ellipses can also be used to demonstrate that a pattern continues, however, this often
can be hazardous as the pattern must be obvious to the reader.
\[
    B = \{1, 2, 3, \ldots\}    
\]
The \textbf{empty set} is also important to note, which defines the set which contains
no elements. It is denoted as $\emptyset$, where for any $x$, $x \notin \emptyset$, and $\emptyset = \{\}$.
\sgap
\sheader{Set Builder Notation} Set builder notation is the general approach to describing sets
with a general rule. A standard form of a set described by set builder notation is as follows:
\begin{align*}
    S = \{\textrm{some expression} \mid \textrm{some rule}\} && S = \{\textrm{a function} \mid \textrm{a domain}\}.
\end{align*}
For example, we can have: 
\begin{align*}
    E &= \{n : n \textrm{ is an even integer}\}\\
    E &= \{n \mid n = 2k \textrm{ for some } k \in \mathbb{Z}\}\\
    E &= \{2n \mid n \in \mathbb{Z}\}.
\end{align*}

\header{Statements and Open Sentences}
\sheader{Statements} A statement is an declarative sentence that can be assigned a truth value.
\gap
\sheader{Open Sentences} An open sentence is a sentence whose truth value depends on another 
``thing'' inside of the sentence. For example, take the sentence/equation:
\[
    x^2 -5x + 4 = 0.
\]
Because no information on the value of $x$ is provided, the truth value of the sentence is unknown.
\gap
\sheader{Negations} Negating a statement requires a full inversion of the \underline{truth table}. 
A negation of a statement $P$ can be denoted as $\sim P$, $!P$ or $\neg P$.
\gap
\header{Logical Operations}
\sheader{Disjunction (Or)} The \textbf{disjunction} of two statements $P$ and $Q$ is 
the statement ``$P$ or $Q$'' and is denoted $P \vee Q$. The disjunction is true if 
at least one of $P$ and $Q$ are true. The disjunction is only false if both $P$ and $Q$ are false.
\sgap
\sheader{Conjunction (And)} The \textbf{conjunction} of two statements $P$ and $Q$ is 
the statement ``$P$ and $Q$'' and is denoted $P \wedge Q$. The conjunction is true when both
$P$ and $Q$ are true. It is false if at least one of $P$ and $Q$ are false.
\gap
\sheader{The Implication} For statements $P$ and $Q$, the \textbf{implications} or \textbf{conditional}
is the statement: if $P$ then $Q$, and is denoted $P \Rightarrow Q$. In this context, we define
\begin{itemize}
    \item $P$ is called the \textbf{hypothesis}
    \item $Q$ is called the \textbf{conclusion}
\end{itemize}
Thus, the only case in which the implication is false is when the hypothesis is true, and
the conclusion is false.
\gap
It is important to note that the implication shares the same truth table as the statement:
\[
    (\sim P) \vee Q .
\]
It is also important to note that the implication is not symmetric. Thus, $P \Rightarrow Q$
is not the same as $Q \Rightarrow P$.
\gap
\header{Implications of the Implication}
\sheader{Modus Ponens} By the truth table of the implication, there is one crucial entry
that makes the basis for proofs. That is when both the hypothesis and the conclusion are true.
Thus, we introduce \textbf{Modus Ponens}, which is the deduction that:
\begin{itemize}
    \item $P$ implies $Q$ is true, and
    \item $P$ is true
    \item Hence, $Q$ must be true
\end{itemize}
Thus, if one can prove that $Q$ is true under the assumption that $P$ is true, then the 
implication is proven. 
\sgap
Modus Ponens also opens the door to chaining conditionals together to prove the original implication.
\gap
\sheader{Modus Tollens} Extrapolating off of Modus Ponens, we can introduce \textbf{Modus Tollens},
which is the deduction:
\begin{itemize}
    \item $P$ implies $Q$ is true, and
    \item $Q$ is false
    \item hence $P$ must be false.
\end{itemize}
This will later be the foundation for the \textit{contrapositive}.
\gap
\sheader{Affirming the Consequent} A common logical error is the \underline{false}
deduction:
\begin{itemize}
    \item $P$ implies $Q$ is true, and
    \item $Q$ is true,
    \item and hence $P$ must be true.
\end{itemize}
This is called \textbf{affirming the consequent} and it is wrong because the flow of logic
is wrong.
\gap
\sheader{Denying the Antecedent} Is another common logical error in which the \textbf{false}
deduction is made that:
\begin{itemize}
    \item $P$ implies $Q$ is true, and
    \item $P$ is false,
    \item and hence $Q$ must be false.
\end{itemize}
\sheader{Negating the Conditional} Since the conditional has the same truth table as
$(\sim P) \vee Q$, we can write the negation of the conditional as $P \wedge (\sim Q)$.
\gap
\sheader{Contrapositive} The \textbf{contrapositive} of an implication is $(\sim Q) \Rightarrow (\sim P)$.
It has the same truth table as the implication, and thus can be used as another method
to prove an implication.
\gap
\sheader{Converse} The \textbf{converse} of an implication is $Q \Rightarrow P$. 
It does not share the same truth table as the implication.
\gap
\sheader{Inverse} The \textbf{inverse} of an implication is $(\sim P) \Rightarrow (\sim Q)$.
It does not share the same truth table as the implication.
\gap
\sheader{Biconditional} The \textbf{biconditional} is where for statements $P$ and $Q$,
$P$ implies $Q$ and $Q$ implies $P$. This can be written as:
\begin{itemize}
    \item $P$ if and only if $Q$
    \item $P$ iff $Q$
    \item $P \Longleftrightarrow Q$.
\end{itemize}

\header{General Overview of Direct Proofs}
Most proofs start with the a conditional that must be proven. Thus, one must demonstrate that
under the hypothesis, the conclusion holds. Many of these proofs have the following form:
\begin{enumerate}
    \item Assume the original statement is true.
    \item Provide an alternative form for the original statement.
    \item Manipulate both sides of the equation until you reach a form that fits the conclusion.
\end{enumerate}

There exist some common methods for proving such 
statements.
\begin{enumerate}
    \item \sheader{Proving the Contrapositive} Instead of proving $P \Rightarrow Q$, one can 
    prove $(\sim Q) \Rightarrow (\sim P)$.
    \sgap
    \sheader{Use Cases}
    \begin{itemize}
        \item To escape having to prove non-divisibilities. 
        \item To escape having to prove something does not have membership.
        \item For when the negation of a statement is simply easier to prove.
    \end{itemize}
    \item \sheader{Proof by Cases} In the case that a statement cannot be proven directly,
    introducing multiple cases which fit the problem favourably can be of assistance.
    \sgap
    \sheader{Use Cases}
    \begin{itemize}
        \item Exploiting divisibilities (cases stem from varying remainder values)
        \item Using all odd/even integers (cases for odd or even integers)
        \item Having permanent signs in statements with \textbf{absolute values}
        \item Proving cases for which a value is in different ranges (generally positive or negative)
    \end{itemize}
\end{enumerate}

There also exist some common practices which are common with many general proofs:
\begin{enumerate}
    \item Using terms to complete the square (often useful with \textbf{inequalities} to demonstrate that a term is positive)
    \item Performing ``ghost operations'' where equations are manipulated in seemingly
    counterintuitive ways $(3 + 2) = 5$ to achieve the desired form.
    \item Exploiting subsets, for example, if you need to prove something for all primes, $P$
    but you can prove it for all odd numbers and 2 ($S$), since all primes are either odd or two,
    then $P \subset S$, so the statement holds for all primes.
\end{enumerate}

\header{Quantifiers}
\underline{Quantifiers} come in two main forms:
\gap
\sheader{The Universal Quantifer} Denoted $\forall$ and is read ``for all''.
\gap
\sheader{The Existential Quantifer} Denoted $\exists$ and is read ``there exists'' or ``at least one''
\gap
Quantifiers help describe how many members of a set fit a certain condition.
\gap
\sheader{Negation of Quantifiers} To negate a quantifier, it is important to note some
main points
\begin{itemize}
    \item The two main quantifiers, $\forall$ and $\exists$ swap.
    \item The domains do not change.
    \item The condition for the members is negated as well.
\end{itemize} 

\header{Bounding Proofs}
A function is \underline{bounded} if it satisfies the following statement:
\[
    \exists M \in \mathbb{R} \suchthat \forall x \in f: A \to \mathbb{R}, |f(x)| \leq M.
\]
\sheader{Bounded Proofs} A bounded proof generally follows the form of:
\begin{enumerate}
    \item Choose an $M(x)$ such that $|f(x)| \leq M$ is satisfied. 
\end{enumerate}
\sheader{Unbounded Proofs} An unbounded proof needs to satisfy the statement:
\[
    \forall M \in \mathbb{R}, \exists x \in f:A \to \mathbb{R} \suchthat |f(x)| > M.
\]
Thus an unbounded proof takes the form of:
\begin{enumerate}
    \item Let $M$ be arbitrary, such that $M \in \mathbb{R}$.
    \item Carefully choose an $x$ value, \underline{generally dependant on $M$}, such that
    $|f(x)| > M$.
\end{enumerate}

\header{Sequence Convergence Proofs}
A sequence $(x_n)$ is said to \underline{converge} to the value $L$ if it satisfies
the following statement:
\[
    \forall \epsilon > 0, \exists N \in \mathbb{N} \suchthat \forall n \in \mathbb{N}, \left(n \geq N \Rightarrow |x_n - L| \leq \epsilon\right).    
\]
\sheader{Convergence Proofs} A convergence proof can generally take the following form:
\begin{enumerate}
    \item Let $\epsilon > 0$ be arbitrary.
    \item Carefully choose some $N$, which is generally \underline{a function of $\epsilon$}. This
    can generally be achieved by holding $|x_n - L| \leq \epsilon$ and solving for $n$.
    \item Assume $n \geq N$ and substitute values to show that $|x_n - L| \leq \epsilon$.
\end{enumerate}
\sheader{Non-Convergence Proofs} The negation of the convergence statement is as follows:
\[
    \exists \epsilon > 0 \suchthat \forall N \in \mathbb{N} , \exists n \in \mathbb{N} \suchthat (n \geq N) \wedge (|x_n -L| > \epsilon).
\]
Common proofs for non-convergence proofs generally resemble:
\begin{enumerate}
    \item Let $N \in \mathbb{N}$ be arbitrary.
    \item Carefully choose $\epsilon$, which is \underline{generally a constant}.
    This is usually obtained by solving $|x_n - L| > \epsilon$.
    \item Choose some value for $n$ such that it fits the inequality $|x_n -L| >\epsilon$.
    Since $n \geq N$ for all $N$, generally, a max function is required, generally of the form:
    $\max\{a, N\}$, where $a$ is some number that minimally satisfies $|x_n - L| > \epsilon$.
\end{enumerate}
\pagebreak
\header{Limit Proofs}
A function $f:A \to R$ has the limit $L$ as $x$ goes to $a$, as denoted by:
\[
    \lim_{x\to a}f(x) = L.    
\]
Thus, to prove a limit, we need to prove the \underline{limit statement} true:
\[
    \forall \epsilon > 0, \exists \delta > 0 \suchthat (0 < |x - a| < \delta) \Rightarrow (|f(x) - L| < \epsilon)    
\]
\sheader{Limit Proofs} A limit proof can generally take the following form:
\begin{enumerate}
    \item Let $\epsilon > 0$ be arbitrary.
    \item Choose $\delta > 0$, which is generally a function of $\epsilon$. It is 
    usually case that to find your $\delta$, one must:
    \begin{itemize}
        \item First try to directly solve $|f(x) - L|< \epsilon$, such that the inequality
        takes the form of $|x - a| < \delta(\epsilon)$. 
        \item However, this is not always the case, generally, when $\delta$ is a function of both 
        $\epsilon$ and $x$, so, it is possible to choose $\delta$ to be a minimum function 
        such that we can manipulate $x$ terms.
    \end{itemize}
    So $\delta$ is generally either some function of $\epsilon$, or some minimum function
    $\delta = \min\{c, g(\epsilon)\}$, where $c$ is some value to make algebra easier.
    \item Starting with $0 < |x - a| < \delta$, use the minimum and/or rearrange the 
    expression to gain information on $x$.
    \item From the minimum function, we can also extrapolate that $|x - a| < \delta \leq g(\epsilon)$.
    \item Using both pieces of information from (3) and (4), $|f(x) - L| < \epsilon$ can be manipulated
    to prove the statement.
\end{enumerate}
\sheader{Triangle Inequality} For limit proofs, and many other proofs, it is important
to note the \underline{triangle inequality}, which states that:
\[
    |x + y| \leq |x| + |y|
\] 
for any real valued $x$, $y$.
\gap
\header{Normal Induction}
Normal Induction proofs rely on being able to prove a \textbf{base case} and then an \textbf{inductive step}.
Normal Induction proofs come in the following forms:
\begin{itemize}
    \item \sheader{Bounding} use the base case and surrounding values to bound the inductive step.
    \item \sheader{Explicit Statements} such as a Fibonacci Series use a recursive definition of a 
    series. Using prior elements of these series generally are the solution to solving these problems.
    \item \sheader{Series} generally use the original series plus an additional term to solve them.
\end{itemize}
\sheader{Inductive Proofs} An inductive proof has the following form:
\gap
\sheader{Statement} 
\[
    \forall n > a, n \in \mathbb{Z}, P(n).
\]
\centertext{Where $a$ is the base case.}
\begin{enumerate}
    \item \sheader{Prove the Base Case} Let $n = a$. Show the reader that $P(a)$ is true.
    \item \sheader{Assume the hypothesis} Assume that $P(k)$ is true. 
    \item \sheader{Prove the Inductive Step} Manipulate $P(k + 1)$ such that $P(k + 1)$ is true.
\end{enumerate}
\sheader{Remark} Often, it is easy to confuse yourself where you are in the proof.
Say that for $P(n)$ to be true, $P(n) = f(n)$. It is important to note that you are
going to be searching for $P(n + 1) = f(n + 1)$, not $P(n + 1) = f(n)$. Thus, it is 
often helpful to write out what $f(n + 1)$ is first, so that you know where you want 
to end up.
\gap

\header{Strong Induction}
Strong induction is where \underline{all} prior cases imply the next case in an
inductive proof.

\section*{Final Exam}

\header{Returning to Sets}

\sheader{Power Sets} A power set of a set $A$, denoted $\mathcal{P}(A)$
is the set of all subsets of $A$. We can also note that if $|A| = n$,
then $|\mathcal{P}(n) = 2^n$.

\sheader{Set Operations}
\begin{itemize}
    \item \sheader{Union} The union of two sets $A$ and $B$ are all of the 
    elements that are in \underline{either} $A$ \textbf{or} $B$, denoted $A \cup B$.
    \item \sheader{Intersection} The intersection of two sets $A$ and $B$ are 
    the elements that are in \underline{both} $A$ \textbf{and} $B$, denoted $A \cap B$.
    \item \sheader{Difference} The difference of two sets $A$ and $B$ is the elements
    which are in $A$, less the elements that are in $B$, denoted $A - B$.
    \item \sheader{Complement} Given a set $A$ which is a subset of a larger set,
    $U$, then the complement of $A$ is all of the elements in $U$ which are not in 
    $A$, denoted $\overline{A}$.
\end{itemize}
\sheader{Cartesian Product} The Cartesian product of two sets $A$ and $B$ is the 
set of ordered pairs containing elements of $A$ and $B$.
\gap
\header{Relations}
We can say that two elements of a set $A$ bear a \underline{relation} to each other 
when they satisfy some rule outlined by the given relation.
\gap
\sheader{Equivalence Relations} Most problems surrounding relations will be in 
the form of equivalence proofs. To prove that a relation is an \underline{equivalence relation},
we must prove the following properties:
\begin{itemize}
    \item \sheader{Reflexivity} $\forall a \in A, aRa$ or $(a, a) \in R$
    \item \sheader{Symmetry} $\forall a, b \in A, aRb \implies bRa$.
    \item \sheader{Transitivity} $\forall a, b, c \in A, ((aRb) \wedge (bRc))\implies aRc$.
\end{itemize}
\sheader{Equivalence Classes} Equivalence classes are all of the elements in a given 
set $A$ which bear an equivalence relation to a chosen element $x$. This is denoted $[x]$.
\begin{align*}
    [x] = \{ a \in A : aRx \}
\end{align*}

\header{Partitions}

A \underline{partition} of a set $A$ is a \textbf{set} $\mathcal{P}$, of non-empty 
subsets of $A$, such that:
\begin{itemize}
    \item If $x \in A$, then there is $X \in \mathcal{P}$ with $x \in X$.
    \item If $X, Y \in \mathcal{P}$, then either $X \cap Y = \emptyset$ or $X = Y$.
\end{itemize}
As a sidenote, the set of equivalence classes on a set $A$ forms a set partition.
\pagebreak
\gap
\sheader{Integers modulo $n$} The equivalence relation $\equiv \Mod{n}$
describes the integers that have the same remainder when divided by $n$.
Hence, we can devine interesting properties on these classes, given some 
$x \in [a]$ and $y \in [b]$, then:
\begin{align*}
    x + y \in [a + b] && xy \in [ab]
\end{align*}
Often, such relations are written $[r]_n$, for $\equiv r \Mod{n}$.
\gap
\header{Functions}
A \underline{function} between two sets, $A$ and $B$ is a non empty subset $f \subseteq A \times B$
such that:
\begin{itemize}
    \item For every $a \in A$, there exists a $b \in B$ such that $(a, b) \in f$.
    \sgap
    \underline{Every input has an output.}
    \item If $(a, b) \in f$ and $(a, c) \in f$, then $b = c$. 
    \sgap
    \underline{Every input has a distinct output.}
\end{itemize}
\sheader{Function Definitions} Given a function $f: A \to B$:
\begin{itemize}
    \item \sheader{Domain} The domain, in this case, $A$, is the \underline{writer-defined}
    set of valid inputs to the function.
    \item \sheader{Codomain} The codomain, in this case, $B$, is the \underline{writer-defined}
    set of valid outputs to the function.
    \item \sheader{Range} The range is all of the \underline{actual} outputs of the 
    function yielded by the domain. We can formalize this by:
    \begin{align*}
        \textrm{rng}(f) = \curly{b \in B \suchthat \exists a \in A \suchthat f(a) = b}
    \end{align*}
    We note that $\textrm{rng}(f) \subseteq B$, or \underline{the range is a subset of the codomain}.
    \sgap
    If we define some additional sets, $C \subseteq A$ and $D \subseteq B$, then we 
    can add some additional definitions:
    \item \sheader{Image} The image of $C$ in $B$ is $f(C) = \curly{f(x) \suchthat x \in C}$.
    In simpler terms, \\\underline{the image is the range of some chosen subset of the domain.}
    \item \sheader{Preimage} The preimage of $D$ in $A$ are all of the elements in $A$ 
    which correspond to outputs in $D$. To formalize:
    \begin{align*}
        f^{-1}(D) = \curly{x \in A \suchthat f(x) \in D}
    \end{align*}
    It is important to note that \underline{the preimage is not the inverse.}
\end{itemize}
\sheader{Identities in Images and Preimages} I feel like these could come in handy.
\sgap
Given some $f: A \to B$, and $C_1, C_2 \subseteq A$ and $D_1, D_2 \subseteq B$:
\begin{align*}
    f(C_1 \cap C_2) &\subseteq f(C_1) \cap f(C_2) & f(C_1 \cup C_2) &= f(C_1) \cup f(C_2)\\
    f^{-1}(D_1 \cap D_2) &= f^{-1}(D_1) \cap f^{-1}(D_2) & f^{-1}(D_1 \cup D_2) &= f^{-1}(D_1) \cup f^{-1}(D_2)
\end{align*}
\pagebreak

\header{Properties of Functions and Function Operations}
We can define some important properties on a given function $f: A \to B$, $a, a_1, a_2 \in A$ and $b, b_1, b_2 \in B$:
\begin{itemize}
    \item \sheader{Injective} We call a function ``injective'' if it follows that 
    \begin{align*}
        (a_1 \neq a_2) \implies (f(a_1) \neq f(a_2))
    \end{align*}
    The contrapositive of this statement is often more useful.
    \item \sheader{Surjective} We call a function ``surjective'' if it follows that 
    \begin{align*}
        \forall b \in B, \exists a \in A \suchthat b = f(a).
    \end{align*}
    \item \sheader{Bijective} We call a function ``bijective'' if it is both 
    injective and surjective. 
\end{itemize}

\sheader{Function Compositions} Given some functions $f: A \to B$ and $g: B \to C$,
we can obtain the \underline{composition} of $f$ and $g$ as $g \circ f: A \to C$.
This can be rewritten as:
\begin{align*}
    (g \circ f)(a) = g(f(a)), \forall a \in A.
\end{align*}
It is important to note that compositions are associative: $h\circ (g\circ f) = (h \circ g) \circ f$.
\gap
Compositions also preserve properties: if a $f$ and $g$ are both in/sur/bi-jective then
$f \circ g$ is also in/sur/bi-jective. 
\gap
We can also define the \underline{partial converses}, which state that:
\begin{itemize}
    \item If $g \circ f$ is an injection, then $f$ is an injection.
    \item If $g \circ f$ is a surjection, then $g$ is a surjection.
\end{itemize}

\header{Proof by Contradiction}
Proof by contradiction is a proof method that generally uses the following logic:
\begin{enumerate}
    \item Assume, to the contrary, a given statemnt is false
    \item Imply that some false statement is true.
    \item By contradiction, the original assumption must be true, as required.
\end{enumerate}
There are some common ways that ``false statements'' present themselves:
\begin{itemize}
    \item \sheader{Equality Contradictions} $0 = 1$ or something of the like.
    \item \sheader{Divisibility Contradictions} $3 \mid 1$ or something of the like.
    \item \sheader{Set Inclusion Contradictions} $1 \in \mathbb{I}$ or something of the like.
\end{itemize}

\header{Inverse Functions}
We can also define different inverses of functions, given some functions $f: A \to B$ and $g: B \to A$:
\begin{itemize}
    \item If $g\circ f = i_A$, we say that $g$ is a \underline{left-inverse} of $f$.
    \item If $f \circ g = i_B$, we say that $g$ is a \underline{right-inverse} of $f$.
    \item If $g$ is \underline{both} a left-inverse and a right-inverse of $f$, then
    we can call $g$ an \underline{inverse} of $f$.
\end{itemize}
Note: $i_A$ denotes the original element in $A$ given to some function when passed
through the function. 
\gap
Inverses have nice relations to function properties, given some $f: A\to B$:
\begin{itemize}
    \item $f$ has a left-inverse iff $f$ is injective.
    \item $f$ has a right-inverse iff $f$ is surjective.
    \item $f$ has an inverse iff $f$ is bijective.
    \item If $f$ has a left-inverse, $g$, and a right-inverse, $h$, then $g = h$.
\end{itemize}

\header{Cardinality of Sets}
We can also discuss the size of sets, or their \underline{cardinalities}.
\gap
As a very important result, we know that for two sets $A$ and $B$, we can state that 
they have the same \underline{cardinality} if $A = B = \emptyset$, or if there exists
a bijection from $A$ to $B$.
\gap
The properties of functions have important implications for cardinality. Given 
some function $f: A \to B$, then 
\begin{itemize}
    \item If $f$ is injective, then $|A| \leq |B|$.
    \item If $f$ is surjective, then $|A| \geq |B|$.
    \item If $f$ is bijective, then $|A| = |B|$.
\end{itemize}

\sheader{Denumerable Sets} We call a set $B$ \underline{denumerable} if we can list 
out its elements. Hence, we can state that there exists a bijection $f: \mathbb{N} \to B$.
Hence, the list has some nice properties:
\begin{itemize}
    \item The list does not repeat ($f$ injective).
    \item Every entry appears at some finite position ($f$ surjective).
\end{itemize}
From this, we can draw some important conclusions:
\begin{itemize}
    \item If $B$ is denumerable, then $A \subseteq B$ implies $A$ is denumerable.
    \item If $A$ and $B$ are denumerable, then $A \cap B$ and $A \cup B$ are denumerable.
    \item If $A$ and $B$ are denumerable, then $A \times B$ is denumerable.
    \item The sets $\mathbb{N}, \mathbb{Z}, \mathbb{Q}$ are all denumerable.
    \item $|A| < |\mathcal{P}(A)|$
\end{itemize}
It is also known that the reals are uncountable.



\end{document}